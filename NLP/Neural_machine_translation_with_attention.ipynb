{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "4JYkgTzrlTap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install Faker\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5eXG9MEhITJ",
        "outputId": "5bb7dea4-f562-4f28-f971-43865f031550"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Faker in /usr/local/lib/python3.10/dist-packages (19.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.10/dist-packages (from Faker) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.4->Faker) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "b_mnIKRIWKMQ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n",
        "from tensorflow.keras.layers import RepeatVector, Dense, Activation, Lambda\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import load_model, Model\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from faker import Faker\n",
        "import random\n",
        "from tqdm import tqdm     #\n",
        "from babel.dates import format_date\n",
        "from test_utils import *\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions for creating dataset"
      ],
      "metadata": {
        "id": "yOWqv_Y1t717"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fake = Faker()\n",
        "Faker.seed(54321)\n",
        "random.seed(54321)\n",
        "\n",
        "# Define format of the dataset we would like to generate\n",
        "FORMATS = ['short',\n",
        "           'medium',\n",
        "           'long',\n",
        "           'full',\n",
        "           'full',\n",
        "           'full',\n",
        "           'full',\n",
        "           'full',\n",
        "           'full',\n",
        "           'full',\n",
        "           'full',\n",
        "           'full',\n",
        "           'full',\n",
        "           'd MMM YYY',\n",
        "           'd MMMM YYY',\n",
        "           'dd MMM YYY',\n",
        "           'd MMM, YYY',\n",
        "           'd MMMM, YYY',\n",
        "           'dd, MMM YYY',\n",
        "           'd MM YY',\n",
        "           'd MMMM YYY',\n",
        "           'MMMM d YYY',\n",
        "           'MMMM d, YYY',\n",
        "           'dd.MM.YY']\n",
        "\n",
        "LOCALES = [\"en_US\"]\n",
        "\n",
        "def load_date():\n",
        "  dt = fake.date_object()\n",
        "  try:\n",
        "    human_readable = format_date(dt, format = random.choice(FORMATS), locale='en_US')\n",
        "    human_readable = human_readable.lower()\n",
        "    human_readable = human_readable.replace(',','')\n",
        "    machine_readable = dt.isoformat()\n",
        "  except AttributeError as e:\n",
        "    return None, None, None\n",
        "  return human_readable, machine_readable, dt\n",
        "\n",
        "def load_dataset(m):\n",
        "  human_vocab = set()\n",
        "  machine_vocab = set()\n",
        "  dataset = []\n",
        "  Tx = 30\n",
        "\n",
        "  for i in tqdm(range(m)):\n",
        "    h, m, _ = load_date()\n",
        "    if h is not None:\n",
        "      dataset.append((h,m))\n",
        "      human_vocab.update(tuple(h))\n",
        "      machine_vocab.update(tuple(m))\n",
        "  human = dict(zip(sorted(human_vocab)+['<unk>', '<pad>'], list(range(len(human_vocab) + 2))))\n",
        "  inv_machine = dict(enumerate(sorted(machine_vocab)))\n",
        "  machine = {v:k for k, v in inv_machine.items()}\n",
        "  return dataset, human, machine, inv_machine\n",
        "\n",
        "\n",
        "def string_to_int(string, length, vocab):\n",
        "  string = string.lower()\n",
        "  string = string.replace(\",\", \"\")\n",
        "\n",
        "  if len(string)> length:\n",
        "    string = string[:length]\n",
        "  rep = list(map(lambda x: vocab.get(x, '<unk>'), string))\n",
        "  if len(string)< length:\n",
        "    rep += [vocab['<pad>']] * (length - len(string))\n",
        "  return rep\n",
        "\n",
        "\n",
        "def int_to_string( ints, inv_vocab):\n",
        "  l = [inv_vocab[i] for i in ints]\n",
        "  return l\n",
        "\n",
        "\n",
        "def preprocess_data(dataset, human_vocab, machine_vocab, Tx, Ty):\n",
        "  X, Y = zip(*dataset)\n",
        "  X = np.array([string_to_int(i, Tx, human_vocab) for i in X])\n",
        "  Y = [string_to_int(t, Ty, machine_vocab) for t in Y]\n",
        "  Xoh = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), X)))\n",
        "  Yoh = np.array(list(map(lambda x: to_categorical(x, num_classes=len(machine_vocab)), Y)))\n",
        "\n",
        "  return X, np.array(Y), Xoh, Yoh\n",
        "\n",
        "def softmax(x, axis=1):\n",
        "    \"\"\"Softmax activation function.\n",
        "    # Arguments\n",
        "        x : Tensor.\n",
        "        axis: Integer, axis along which the softmax normalization is applied.\n",
        "    # Returns\n",
        "        Tensor, output of softmax transformation.\n",
        "    # Raises\n",
        "        ValueError: In case `dim(x) == 1`.\n",
        "    \"\"\"\n",
        "    ndim = K.ndim(x)\n",
        "    if ndim == 2:\n",
        "        return K.softmax(x)\n",
        "    elif ndim > 2:\n",
        "        e = K.exp(x - K.max(x, axis=axis, keepdims=True))\n",
        "        s = K.sum(e, axis=axis, keepdims=True)\n",
        "        return e / s\n",
        "    else:\n",
        "        raise ValueError('Cannot apply softmax to a tensor that is 1D')\n",
        "\n"
      ],
      "metadata": {
        "id": "NRD1yNVTcOrK"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "Bj_9kAKruR6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = 10000\n",
        "dataset, human_vocab, machine_vocab, inv_machine_vocab = load_dataset(m)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aovTuQuKuVRT",
        "outputId": "b931522e-6aee-44d1-f202-fed6dd4dea31"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [00:00<00:00, 23479.59it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJrDWnByuoIn",
        "outputId": "acb2bb38-7ccc-474d-b6f3-e364bcda0ff8"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('03 apr 2003', '2003-04-03'),\n",
              " ('march 30 2023', '2023-03-30'),\n",
              " ('sunday september 22 1974', '1974-09-22'),\n",
              " ('saturday august 23 1986', '1986-08-23'),\n",
              " ('14 august 1981', '1981-08-14'),\n",
              " ('15 aug 2007', '2007-08-15'),\n",
              " ('saturday december 17 2005', '2005-12-17'),\n",
              " ('tuesday september 17 1996', '1996-09-17'),\n",
              " ('friday december 4 1981', '1981-12-04'),\n",
              " ('6 jan 1992', '1992-01-06')]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(machine_vocab))\n",
        "print(len(human_vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xisq_QIqHpYZ",
        "outputId": "2ae5ece5-2b61-431f-d1cb-6e1f9d71283d"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11\n",
            "37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Tx =30\n",
        "Ty = 10\n",
        "\n",
        "X,Y, Xoh, Yoh = preprocess_data(dataset, human_vocab, machine_vocab, Tx, Ty)"
      ],
      "metadata": {
        "id": "NHrwrzbhu38v"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X.shape:\", X.shape)\n",
        "print(\"Y.shape:\", Y.shape)\n",
        "print(\"Xoh.shape:\", Xoh.shape)\n",
        "print(\"Yoh.shape:\", Yoh.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nXVdFDgHIXn",
        "outputId": "60011079-7c63-4b38-fe16-7c279e302448"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X.shape: (10000, 30)\n",
            "Y.shape: (10000, 10)\n",
            "Xoh.shape: (10000, 30, 37)\n",
            "Yoh.shape: (10000, 10, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3VWe67JuHKsB"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## one_step_attention"
      ],
      "metadata": {
        "id": "qvOr-IytMZ-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "repeator = RepeatVector(Tx)\n",
        "concatenator = Concatenate(axis=-1)\n",
        "densor1 = Dense(10, activation = \"tanh\")\n",
        "densor2 = Dense(1, activation = \"relu\")\n",
        "activator = Activation(softmax, name='attention_weights')\n",
        "dotor = Dot(axes = 1)"
      ],
      "metadata": {
        "id": "NPjMkm3mJuKy"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_step_attention(a, s_prev):\n",
        "# Use repeator to repeat s_prev to be of shape (m, Tx, n_s) so that you can concatenate it with all hidden states \"a\"\n",
        "  s_prev = repeator(s_prev)\n",
        "#Use concatenator to concatenate a and s_prev on the last axi\n",
        "  concat = concatenator([a, s_prev])\n",
        "# Use densor1 to propagate concat through a small fully-connected neural network to compute the \"intermediate energies\" variable e.\n",
        "\n",
        "  e = densor1(concat)\n",
        "# Use densor2 to propagate e through a small fully-connected neural network to compute the \"energies\" variable energies.\n",
        "\n",
        "  energies = densor2(e)\n",
        "# Use \"activator\" on \"energies\" to compute the attention weights \"alphas\"\n",
        "\n",
        "  alphas = activator(energies)\n",
        "# Use dotor together with \"alphas\" and \"a\", in this order, to compute the context vector to be given to the next (post-attention) LSTM-cell (≈ 1 line)\n",
        "\n",
        "  context = dotor([alphas, a])\n",
        "\n",
        "  return context"
      ],
      "metadata": {
        "id": "ZeUnEuiFMqkd"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vGw88sq2vUlY"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "Yj0JOtatLugG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_a = 32 #number of units for the pre_attention , bi-directional LSTM's hidden state \"a\"\n",
        "n_s = 64 #number of units for the post-attention LSTM's hidden state \"s\"\n",
        "post_activation_LSTM_cell = LSTM(n_s, return_state= True)\n",
        "output_layer = Dense(len(machine_vocab),  activation = softmax)"
      ],
      "metadata": {
        "id": "27UKFA1rLw_J"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def modelf(Tx, Ty, n_a, n_s, human_vocab_size, machine_vocab_size):\n",
        "    # Define the inputs of your model with a shape (Tx, human_vocab_size)\n",
        "  X =Input(shape=(Tx, human_vocab_size))\n",
        "    # Define s0 (initial hidden state) and c0 (initial cell state)\n",
        "  s0 = Input(shape=(n_s,), name= 's0')\n",
        "  c0 = Input(shape= (n_s,), name= 'c0')\n",
        "\n",
        "  s = s0\n",
        "  c = c0\n",
        "  # initilize the empty list of outputs\n",
        "  outputs = []\n",
        "  # Define your pre attention Bi-LSTM\n",
        "\n",
        "  a = Bidirectional(LSTM(n_a, return_sequences=True))(X)\n",
        "\n",
        "  for t in range(Ty):\n",
        "    context = one_step_attention(a,s)\n",
        "\n",
        "    _, s, c = post_activation_LSTM_cell(context, initial_state = [s,c])\n",
        "\n",
        "    out = output_layer(s)\n",
        "    outputs.append(out)\n",
        "    model = Model( inputs=[X,s0,c0], outputs = outputs)\n",
        "\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "gF9qS0tLkK7c"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fo6lQHXqvunQ",
        "outputId": "a520b741-6500-4b5c-c68a-fac2074d78fc"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = modelf(Tx, Ty, n_a, n_s, len(human_vocab), len(machine_vocab))"
      ],
      "metadata": {
        "id": "eciqZSSVqSz1"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krXyUneGqknL",
        "outputId": "6f481cf7-7a9f-43eb-b732-40c70fd2e76a"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_45\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_21 (InputLayer)       [(None, 30, 37)]             0         []                            \n",
            "                                                                                                  \n",
            " s0 (InputLayer)             [(None, 64)]                 0         []                            \n",
            "                                                                                                  \n",
            " bidirectional_20 (Bidirect  (None, 30, 64)               17920     ['input_21[0][0]']            \n",
            " ional)                                                                                           \n",
            "                                                                                                  \n",
            " repeat_vector_3 (RepeatVec  (None, 30, 64)               0         ['s0[0][0]',                  \n",
            " tor)                                                                'lstm_24[0][1]',             \n",
            "                                                                     'lstm_24[1][1]',             \n",
            "                                                                     'lstm_24[2][1]',             \n",
            "                                                                     'lstm_24[3][1]',             \n",
            "                                                                     'lstm_24[4][1]',             \n",
            "                                                                     'lstm_24[5][1]',             \n",
            "                                                                     'lstm_24[6][1]',             \n",
            "                                                                     'lstm_24[7][1]',             \n",
            "                                                                     'lstm_24[8][1]']             \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate  (None, 30, 128)              0         ['bidirectional_20[0][0]',    \n",
            " )                                                                   'repeat_vector_3[54][0]',    \n",
            "                                                                     'bidirectional_20[0][0]',    \n",
            "                                                                     'repeat_vector_3[55][0]',    \n",
            "                                                                     'bidirectional_20[0][0]',    \n",
            "                                                                     'repeat_vector_3[56][0]',    \n",
            "                                                                     'bidirectional_20[0][0]',    \n",
            "                                                                     'repeat_vector_3[57][0]',    \n",
            "                                                                     'bidirectional_20[0][0]',    \n",
            "                                                                     'repeat_vector_3[58][0]',    \n",
            "                                                                     'bidirectional_20[0][0]',    \n",
            "                                                                     'repeat_vector_3[59][0]',    \n",
            "                                                                     'bidirectional_20[0][0]',    \n",
            "                                                                     'repeat_vector_3[60][0]',    \n",
            "                                                                     'bidirectional_20[0][0]',    \n",
            "                                                                     'repeat_vector_3[61][0]',    \n",
            "                                                                     'bidirectional_20[0][0]',    \n",
            "                                                                     'repeat_vector_3[62][0]',    \n",
            "                                                                     'bidirectional_20[0][0]',    \n",
            "                                                                     'repeat_vector_3[63][0]']    \n",
            "                                                                                                  \n",
            " dense_7 (Dense)             (None, 30, 10)               1290      ['concatenate_3[54][0]',      \n",
            "                                                                     'concatenate_3[55][0]',      \n",
            "                                                                     'concatenate_3[56][0]',      \n",
            "                                                                     'concatenate_3[57][0]',      \n",
            "                                                                     'concatenate_3[58][0]',      \n",
            "                                                                     'concatenate_3[59][0]',      \n",
            "                                                                     'concatenate_3[60][0]',      \n",
            "                                                                     'concatenate_3[61][0]',      \n",
            "                                                                     'concatenate_3[62][0]',      \n",
            "                                                                     'concatenate_3[63][0]']      \n",
            "                                                                                                  \n",
            " dense_8 (Dense)             (None, 30, 1)                11        ['dense_7[54][0]',            \n",
            "                                                                     'dense_7[55][0]',            \n",
            "                                                                     'dense_7[56][0]',            \n",
            "                                                                     'dense_7[57][0]',            \n",
            "                                                                     'dense_7[58][0]',            \n",
            "                                                                     'dense_7[59][0]',            \n",
            "                                                                     'dense_7[60][0]',            \n",
            "                                                                     'dense_7[61][0]',            \n",
            "                                                                     'dense_7[62][0]',            \n",
            "                                                                     'dense_7[63][0]']            \n",
            "                                                                                                  \n",
            " attention_weights (Activat  (None, 30, 1)                0         ['dense_8[54][0]',            \n",
            " ion)                                                                'dense_8[55][0]',            \n",
            "                                                                     'dense_8[56][0]',            \n",
            "                                                                     'dense_8[57][0]',            \n",
            "                                                                     'dense_8[58][0]',            \n",
            "                                                                     'dense_8[59][0]',            \n",
            "                                                                     'dense_8[60][0]',            \n",
            "                                                                     'dense_8[61][0]',            \n",
            "                                                                     'dense_8[62][0]',            \n",
            "                                                                     'dense_8[63][0]']            \n",
            "                                                                                                  \n",
            " dot_3 (Dot)                 (None, 1, 64)                0         ['attention_weights[54][0]',  \n",
            "                                                                     'bidirectional_20[0][0]',    \n",
            "                                                                     'attention_weights[55][0]',  \n",
            "                                                                     'bidirectional_20[0][0]',    \n",
            "                                                                     'attention_weights[56][0]',  \n",
            "                                                                     'bidirectional_20[0][0]',    \n",
            "                                                                     'attention_weights[57][0]',  \n",
            "                                                                     'bidirectional_20[0][0]',    \n",
            "                                                                     'attention_weights[58][0]',  \n",
            "                                                                     'bidirectional_20[0][0]',    \n",
            "                                                                     'attention_weights[59][0]',  \n",
            "                                                                     'bidirectional_20[0][0]',    \n",
            "                                                                     'attention_weights[60][0]',  \n",
            "                                                                     'bidirectional_20[0][0]',    \n",
            "                                                                     'attention_weights[61][0]',  \n",
            "                                                                     'bidirectional_20[0][0]',    \n",
            "                                                                     'attention_weights[62][0]',  \n",
            "                                                                     'bidirectional_20[0][0]',    \n",
            "                                                                     'attention_weights[63][0]',  \n",
            "                                                                     'bidirectional_20[0][0]']    \n",
            "                                                                                                  \n",
            " c0 (InputLayer)             [(None, 64)]                 0         []                            \n",
            "                                                                                                  \n",
            " lstm_24 (LSTM)              [(None, 64),                 33024     ['dot_3[54][0]',              \n",
            "                              (None, 64),                            's0[0][0]',                  \n",
            "                              (None, 64)]                            'c0[0][0]',                  \n",
            "                                                                     'dot_3[55][0]',              \n",
            "                                                                     'lstm_24[0][1]',             \n",
            "                                                                     'lstm_24[0][2]',             \n",
            "                                                                     'dot_3[56][0]',              \n",
            "                                                                     'lstm_24[1][1]',             \n",
            "                                                                     'lstm_24[1][2]',             \n",
            "                                                                     'dot_3[57][0]',              \n",
            "                                                                     'lstm_24[2][1]',             \n",
            "                                                                     'lstm_24[2][2]',             \n",
            "                                                                     'dot_3[58][0]',              \n",
            "                                                                     'lstm_24[3][1]',             \n",
            "                                                                     'lstm_24[3][2]',             \n",
            "                                                                     'dot_3[59][0]',              \n",
            "                                                                     'lstm_24[4][1]',             \n",
            "                                                                     'lstm_24[4][2]',             \n",
            "                                                                     'dot_3[60][0]',              \n",
            "                                                                     'lstm_24[5][1]',             \n",
            "                                                                     'lstm_24[5][2]',             \n",
            "                                                                     'dot_3[61][0]',              \n",
            "                                                                     'lstm_24[6][1]',             \n",
            "                                                                     'lstm_24[6][2]',             \n",
            "                                                                     'dot_3[62][0]',              \n",
            "                                                                     'lstm_24[7][1]',             \n",
            "                                                                     'lstm_24[7][2]',             \n",
            "                                                                     'dot_3[63][0]',              \n",
            "                                                                     'lstm_24[8][1]',             \n",
            "                                                                     'lstm_24[8][2]']             \n",
            "                                                                                                  \n",
            " dense_11 (Dense)            (None, 11)                   715       ['lstm_24[0][1]',             \n",
            "                                                                     'lstm_24[1][1]',             \n",
            "                                                                     'lstm_24[2][1]',             \n",
            "                                                                     'lstm_24[3][1]',             \n",
            "                                                                     'lstm_24[4][1]',             \n",
            "                                                                     'lstm_24[5][1]',             \n",
            "                                                                     'lstm_24[6][1]',             \n",
            "                                                                     'lstm_24[7][1]',             \n",
            "                                                                     'lstm_24[8][1]',             \n",
            "                                                                     'lstm_24[9][1]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 52960 (206.88 KB)\n",
            "Trainable params: 52960 (206.88 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt = Adam( learning_rate = 0.005, beta_1 = 0.9, beta_2 = 0.999)\n",
        "model.compile(loss = \"categorical_crossentropy\", optimizer = opt, metrics = [\"accuracy\"])"
      ],
      "metadata": {
        "id": "R6qXNAUwqmvU"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s0 = np.zeros((m, n_s))\n",
        "c0 = np.zeros((m, n_s))\n",
        "outputs = list(Yoh.swapaxes(0,1))"
      ],
      "metadata": {
        "id": "2cnjyf9XtQGU"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit([Xoh, s0, c0], outputs, epochs=20, batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zr91mtfctbBn",
        "outputId": "9f59360a-5bb1-4a9f-d2b9-d5c7812d5337"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "79/79 [==============================] - 38s 130ms/step - loss: 17.2663 - dense_11_loss: 1.2437 - dense_11_1_loss: 1.1205 - dense_11_2_loss: 1.8458 - dense_11_3_loss: 2.6457 - dense_11_4_loss: 0.8226 - dense_11_5_loss: 1.3387 - dense_11_6_loss: 2.6827 - dense_11_7_loss: 1.1578 - dense_11_8_loss: 1.7977 - dense_11_9_loss: 2.6110 - dense_11_accuracy: 0.4983 - dense_11_1_accuracy: 0.6394 - dense_11_2_accuracy: 0.2766 - dense_11_3_accuracy: 0.1015 - dense_11_4_accuracy: 0.9336 - dense_11_5_accuracy: 0.3156 - dense_11_6_accuracy: 0.0344 - dense_11_7_accuracy: 0.8148 - dense_11_8_accuracy: 0.2306 - dense_11_9_accuracy: 0.1087\n",
            "Epoch 2/20\n",
            "79/79 [==============================] - 10s 131ms/step - loss: 8.7106 - dense_11_loss: 0.1966 - dense_11_1_loss: 0.1400 - dense_11_2_loss: 1.0806 - dense_11_3_loss: 2.0987 - dense_11_4_loss: 0.0156 - dense_11_5_loss: 0.2371 - dense_11_6_loss: 1.7259 - dense_11_7_loss: 0.0145 - dense_11_8_loss: 1.1364 - dense_11_9_loss: 2.0653 - dense_11_accuracy: 0.9567 - dense_11_1_accuracy: 0.9608 - dense_11_2_accuracy: 0.5160 - dense_11_3_accuracy: 0.2325 - dense_11_4_accuracy: 1.0000 - dense_11_5_accuracy: 0.9241 - dense_11_6_accuracy: 0.3595 - dense_11_7_accuracy: 0.9999 - dense_11_8_accuracy: 0.4837 - dense_11_9_accuracy: 0.2324\n",
            "Epoch 3/20\n",
            "79/79 [==============================] - 11s 136ms/step - loss: 7.1064 - dense_11_loss: 0.0986 - dense_11_1_loss: 0.0841 - dense_11_2_loss: 0.9710 - dense_11_3_loss: 1.8164 - dense_11_4_loss: 0.0069 - dense_11_5_loss: 0.1359 - dense_11_6_loss: 1.2602 - dense_11_7_loss: 0.0082 - dense_11_8_loss: 0.9140 - dense_11_9_loss: 1.8113 - dense_11_accuracy: 0.9710 - dense_11_1_accuracy: 0.9717 - dense_11_2_accuracy: 0.5684 - dense_11_3_accuracy: 0.3407 - dense_11_4_accuracy: 0.9999 - dense_11_5_accuracy: 0.9584 - dense_11_6_accuracy: 0.5581 - dense_11_7_accuracy: 0.9998 - dense_11_8_accuracy: 0.5903 - dense_11_9_accuracy: 0.3231\n",
            "Epoch 4/20\n",
            "79/79 [==============================] - 9s 117ms/step - loss: 5.8655 - dense_11_loss: 0.0753 - dense_11_1_loss: 0.0647 - dense_11_2_loss: 0.8525 - dense_11_3_loss: 1.3719 - dense_11_4_loss: 0.0050 - dense_11_5_loss: 0.1209 - dense_11_6_loss: 1.0205 - dense_11_7_loss: 0.0066 - dense_11_8_loss: 0.7953 - dense_11_9_loss: 1.5528 - dense_11_accuracy: 0.9758 - dense_11_1_accuracy: 0.9779 - dense_11_2_accuracy: 0.6309 - dense_11_3_accuracy: 0.5129 - dense_11_4_accuracy: 0.9999 - dense_11_5_accuracy: 0.9641 - dense_11_6_accuracy: 0.6318 - dense_11_7_accuracy: 0.9999 - dense_11_8_accuracy: 0.6621 - dense_11_9_accuracy: 0.4171\n",
            "Epoch 5/20\n",
            "79/79 [==============================] - 10s 133ms/step - loss: 3.8810 - dense_11_loss: 0.0647 - dense_11_1_loss: 0.0478 - dense_11_2_loss: 0.5712 - dense_11_3_loss: 0.4989 - dense_11_4_loss: 0.0053 - dense_11_5_loss: 0.1012 - dense_11_6_loss: 0.8042 - dense_11_7_loss: 0.0054 - dense_11_8_loss: 0.6760 - dense_11_9_loss: 1.1064 - dense_11_accuracy: 0.9789 - dense_11_1_accuracy: 0.9827 - dense_11_2_accuracy: 0.7683 - dense_11_3_accuracy: 0.8643 - dense_11_4_accuracy: 0.9997 - dense_11_5_accuracy: 0.9710 - dense_11_6_accuracy: 0.7235 - dense_11_7_accuracy: 0.9996 - dense_11_8_accuracy: 0.7312 - dense_11_9_accuracy: 0.5981\n",
            "Epoch 6/20\n",
            "79/79 [==============================] - 11s 136ms/step - loss: 2.0774 - dense_11_loss: 0.0490 - dense_11_1_loss: 0.0366 - dense_11_2_loss: 0.1142 - dense_11_3_loss: 0.1247 - dense_11_4_loss: 0.0024 - dense_11_5_loss: 0.0803 - dense_11_6_loss: 0.5179 - dense_11_7_loss: 0.0038 - dense_11_8_loss: 0.5199 - dense_11_9_loss: 0.6286 - dense_11_accuracy: 0.9834 - dense_11_1_accuracy: 0.9852 - dense_11_2_accuracy: 0.9783 - dense_11_3_accuracy: 0.9910 - dense_11_4_accuracy: 1.0000 - dense_11_5_accuracy: 0.9756 - dense_11_6_accuracy: 0.8463 - dense_11_7_accuracy: 1.0000 - dense_11_8_accuracy: 0.8110 - dense_11_9_accuracy: 0.7859\n",
            "Epoch 7/20\n",
            "79/79 [==============================] - 11s 136ms/step - loss: 1.4037 - dense_11_loss: 0.0358 - dense_11_1_loss: 0.0248 - dense_11_2_loss: 0.0206 - dense_11_3_loss: 0.0575 - dense_11_4_loss: 0.0013 - dense_11_5_loss: 0.0632 - dense_11_6_loss: 0.3511 - dense_11_7_loss: 0.0028 - dense_11_8_loss: 0.4129 - dense_11_9_loss: 0.4337 - dense_11_accuracy: 0.9889 - dense_11_1_accuracy: 0.9905 - dense_11_2_accuracy: 0.9995 - dense_11_3_accuracy: 0.9972 - dense_11_4_accuracy: 1.0000 - dense_11_5_accuracy: 0.9808 - dense_11_6_accuracy: 0.9056 - dense_11_7_accuracy: 1.0000 - dense_11_8_accuracy: 0.8514 - dense_11_9_accuracy: 0.8438\n",
            "Epoch 8/20\n",
            "79/79 [==============================] - 9s 115ms/step - loss: 1.0561 - dense_11_loss: 0.0167 - dense_11_1_loss: 0.0073 - dense_11_2_loss: 0.0094 - dense_11_3_loss: 0.0421 - dense_11_4_loss: 8.9911e-04 - dense_11_5_loss: 0.0558 - dense_11_6_loss: 0.2683 - dense_11_7_loss: 0.0023 - dense_11_8_loss: 0.3260 - dense_11_9_loss: 0.3273 - dense_11_accuracy: 0.9960 - dense_11_1_accuracy: 0.9982 - dense_11_2_accuracy: 0.9997 - dense_11_3_accuracy: 0.9977 - dense_11_4_accuracy: 1.0000 - dense_11_5_accuracy: 0.9808 - dense_11_6_accuracy: 0.9239 - dense_11_7_accuracy: 0.9999 - dense_11_8_accuracy: 0.8765 - dense_11_9_accuracy: 0.8784\n",
            "Epoch 9/20\n",
            "79/79 [==============================] - 11s 135ms/step - loss: 0.8344 - dense_11_loss: 0.0078 - dense_11_1_loss: 0.0027 - dense_11_2_loss: 0.0070 - dense_11_3_loss: 0.0339 - dense_11_4_loss: 7.3423e-04 - dense_11_5_loss: 0.0468 - dense_11_6_loss: 0.2208 - dense_11_7_loss: 0.0017 - dense_11_8_loss: 0.2576 - dense_11_9_loss: 0.2554 - dense_11_accuracy: 0.9991 - dense_11_1_accuracy: 0.9997 - dense_11_2_accuracy: 0.9997 - dense_11_3_accuracy: 0.9976 - dense_11_4_accuracy: 1.0000 - dense_11_5_accuracy: 0.9840 - dense_11_6_accuracy: 0.9375 - dense_11_7_accuracy: 1.0000 - dense_11_8_accuracy: 0.9031 - dense_11_9_accuracy: 0.9016\n",
            "Epoch 10/20\n",
            "79/79 [==============================] - 11s 136ms/step - loss: 0.6515 - dense_11_loss: 0.0047 - dense_11_1_loss: 0.0016 - dense_11_2_loss: 0.0051 - dense_11_3_loss: 0.0291 - dense_11_4_loss: 4.2421e-04 - dense_11_5_loss: 0.0380 - dense_11_6_loss: 0.1739 - dense_11_7_loss: 0.0016 - dense_11_8_loss: 0.1894 - dense_11_9_loss: 0.2077 - dense_11_accuracy: 0.9997 - dense_11_1_accuracy: 1.0000 - dense_11_2_accuracy: 0.9998 - dense_11_3_accuracy: 0.9978 - dense_11_4_accuracy: 1.0000 - dense_11_5_accuracy: 0.9872 - dense_11_6_accuracy: 0.9491 - dense_11_7_accuracy: 0.9999 - dense_11_8_accuracy: 0.9321 - dense_11_9_accuracy: 0.9197\n",
            "Epoch 11/20\n",
            "79/79 [==============================] - 11s 135ms/step - loss: 0.5123 - dense_11_loss: 0.0032 - dense_11_1_loss: 0.0013 - dense_11_2_loss: 0.0046 - dense_11_3_loss: 0.0260 - dense_11_4_loss: 4.0350e-04 - dense_11_5_loss: 0.0336 - dense_11_6_loss: 0.1474 - dense_11_7_loss: 0.0015 - dense_11_8_loss: 0.1314 - dense_11_9_loss: 0.1629 - dense_11_accuracy: 0.9997 - dense_11_1_accuracy: 0.9999 - dense_11_2_accuracy: 0.9998 - dense_11_3_accuracy: 0.9978 - dense_11_4_accuracy: 1.0000 - dense_11_5_accuracy: 0.9887 - dense_11_6_accuracy: 0.9573 - dense_11_7_accuracy: 1.0000 - dense_11_8_accuracy: 0.9581 - dense_11_9_accuracy: 0.9452\n",
            "Epoch 12/20\n",
            "79/79 [==============================] - 9s 118ms/step - loss: 0.4198 - dense_11_loss: 0.0026 - dense_11_1_loss: 0.0013 - dense_11_2_loss: 0.0042 - dense_11_3_loss: 0.0258 - dense_11_4_loss: 3.0284e-04 - dense_11_5_loss: 0.0310 - dense_11_6_loss: 0.1290 - dense_11_7_loss: 0.0015 - dense_11_8_loss: 0.0981 - dense_11_9_loss: 0.1261 - dense_11_accuracy: 0.9999 - dense_11_1_accuracy: 1.0000 - dense_11_2_accuracy: 0.9999 - dense_11_3_accuracy: 0.9976 - dense_11_4_accuracy: 1.0000 - dense_11_5_accuracy: 0.9894 - dense_11_6_accuracy: 0.9617 - dense_11_7_accuracy: 0.9998 - dense_11_8_accuracy: 0.9689 - dense_11_9_accuracy: 0.9614\n",
            "Epoch 13/20\n",
            "79/79 [==============================] - 10s 131ms/step - loss: 0.2839 - dense_11_loss: 0.0019 - dense_11_1_loss: 9.3989e-04 - dense_11_2_loss: 0.0034 - dense_11_3_loss: 0.0225 - dense_11_4_loss: 2.9517e-04 - dense_11_5_loss: 0.0272 - dense_11_6_loss: 0.1043 - dense_11_7_loss: 9.7152e-04 - dense_11_8_loss: 0.0476 - dense_11_9_loss: 0.0747 - dense_11_accuracy: 0.9999 - dense_11_1_accuracy: 1.0000 - dense_11_2_accuracy: 0.9999 - dense_11_3_accuracy: 0.9978 - dense_11_4_accuracy: 1.0000 - dense_11_5_accuracy: 0.9906 - dense_11_6_accuracy: 0.9670 - dense_11_7_accuracy: 1.0000 - dense_11_8_accuracy: 0.9906 - dense_11_9_accuracy: 0.9809\n",
            "Epoch 14/20\n",
            "79/79 [==============================] - 11s 134ms/step - loss: 0.2397 - dense_11_loss: 0.0016 - dense_11_1_loss: 7.8338e-04 - dense_11_2_loss: 0.0027 - dense_11_3_loss: 0.0212 - dense_11_4_loss: 1.8854e-04 - dense_11_5_loss: 0.0232 - dense_11_6_loss: 0.0871 - dense_11_7_loss: 9.0634e-04 - dense_11_8_loss: 0.0382 - dense_11_9_loss: 0.0638 - dense_11_accuracy: 0.9999 - dense_11_1_accuracy: 1.0000 - dense_11_2_accuracy: 0.9999 - dense_11_3_accuracy: 0.9978 - dense_11_4_accuracy: 1.0000 - dense_11_5_accuracy: 0.9916 - dense_11_6_accuracy: 0.9736 - dense_11_7_accuracy: 0.9999 - dense_11_8_accuracy: 0.9922 - dense_11_9_accuracy: 0.9833\n",
            "Epoch 15/20\n",
            "79/79 [==============================] - 11s 136ms/step - loss: 0.1844 - dense_11_loss: 0.0012 - dense_11_1_loss: 7.2108e-04 - dense_11_2_loss: 0.0025 - dense_11_3_loss: 0.0195 - dense_11_4_loss: 2.0046e-04 - dense_11_5_loss: 0.0204 - dense_11_6_loss: 0.0716 - dense_11_7_loss: 5.8371e-04 - dense_11_8_loss: 0.0230 - dense_11_9_loss: 0.0446 - dense_11_accuracy: 1.0000 - dense_11_1_accuracy: 1.0000 - dense_11_2_accuracy: 0.9999 - dense_11_3_accuracy: 0.9978 - dense_11_4_accuracy: 1.0000 - dense_11_5_accuracy: 0.9937 - dense_11_6_accuracy: 0.9780 - dense_11_7_accuracy: 1.0000 - dense_11_8_accuracy: 0.9962 - dense_11_9_accuracy: 0.9893\n",
            "Epoch 16/20\n",
            "79/79 [==============================] - 10s 121ms/step - loss: 0.1662 - dense_11_loss: 9.6587e-04 - dense_11_1_loss: 6.2928e-04 - dense_11_2_loss: 0.0023 - dense_11_3_loss: 0.0185 - dense_11_4_loss: 1.9161e-04 - dense_11_5_loss: 0.0190 - dense_11_6_loss: 0.0642 - dense_11_7_loss: 5.7730e-04 - dense_11_8_loss: 0.0224 - dense_11_9_loss: 0.0375 - dense_11_accuracy: 1.0000 - dense_11_1_accuracy: 1.0000 - dense_11_2_accuracy: 0.9998 - dense_11_3_accuracy: 0.9978 - dense_11_4_accuracy: 1.0000 - dense_11_5_accuracy: 0.9927 - dense_11_6_accuracy: 0.9808 - dense_11_7_accuracy: 1.0000 - dense_11_8_accuracy: 0.9954 - dense_11_9_accuracy: 0.9900\n",
            "Epoch 17/20\n",
            "79/79 [==============================] - 10s 131ms/step - loss: 0.1280 - dense_11_loss: 7.6536e-04 - dense_11_1_loss: 6.2137e-04 - dense_11_2_loss: 0.0023 - dense_11_3_loss: 0.0178 - dense_11_4_loss: 1.4119e-04 - dense_11_5_loss: 0.0175 - dense_11_6_loss: 0.0507 - dense_11_7_loss: 4.8176e-04 - dense_11_8_loss: 0.0123 - dense_11_9_loss: 0.0254 - dense_11_accuracy: 1.0000 - dense_11_1_accuracy: 0.9999 - dense_11_2_accuracy: 0.9998 - dense_11_3_accuracy: 0.9977 - dense_11_4_accuracy: 1.0000 - dense_11_5_accuracy: 0.9941 - dense_11_6_accuracy: 0.9852 - dense_11_7_accuracy: 1.0000 - dense_11_8_accuracy: 0.9985 - dense_11_9_accuracy: 0.9944\n",
            "Epoch 18/20\n",
            "79/79 [==============================] - 11s 136ms/step - loss: 0.1321 - dense_11_loss: 7.9722e-04 - dense_11_1_loss: 4.6612e-04 - dense_11_2_loss: 0.0020 - dense_11_3_loss: 0.0174 - dense_11_4_loss: 1.5744e-04 - dense_11_5_loss: 0.0190 - dense_11_6_loss: 0.0536 - dense_11_7_loss: 4.5732e-04 - dense_11_8_loss: 0.0115 - dense_11_9_loss: 0.0268 - dense_11_accuracy: 1.0000 - dense_11_1_accuracy: 1.0000 - dense_11_2_accuracy: 0.9999 - dense_11_3_accuracy: 0.9979 - dense_11_4_accuracy: 1.0000 - dense_11_5_accuracy: 0.9935 - dense_11_6_accuracy: 0.9836 - dense_11_7_accuracy: 1.0000 - dense_11_8_accuracy: 0.9985 - dense_11_9_accuracy: 0.9931\n",
            "Epoch 19/20\n",
            "79/79 [==============================] - 11s 134ms/step - loss: 0.0832 - dense_11_loss: 5.8778e-04 - dense_11_1_loss: 3.6103e-04 - dense_11_2_loss: 0.0016 - dense_11_3_loss: 0.0154 - dense_11_4_loss: 1.4386e-04 - dense_11_5_loss: 0.0094 - dense_11_6_loss: 0.0309 - dense_11_7_loss: 3.2905e-04 - dense_11_8_loss: 0.0082 - dense_11_9_loss: 0.0162 - dense_11_accuracy: 1.0000 - dense_11_1_accuracy: 1.0000 - dense_11_2_accuracy: 0.9999 - dense_11_3_accuracy: 0.9977 - dense_11_4_accuracy: 1.0000 - dense_11_5_accuracy: 0.9972 - dense_11_6_accuracy: 0.9920 - dense_11_7_accuracy: 1.0000 - dense_11_8_accuracy: 0.9995 - dense_11_9_accuracy: 0.9971\n",
            "Epoch 20/20\n",
            "79/79 [==============================] - 9s 117ms/step - loss: 0.2338 - dense_11_loss: 9.7758e-04 - dense_11_1_loss: 0.0012 - dense_11_2_loss: 0.0090 - dense_11_3_loss: 0.0251 - dense_11_4_loss: 0.0010 - dense_11_5_loss: 0.0180 - dense_11_6_loss: 0.0622 - dense_11_7_loss: 0.0023 - dense_11_8_loss: 0.0458 - dense_11_9_loss: 0.0683 - dense_11_accuracy: 0.9999 - dense_11_1_accuracy: 0.9998 - dense_11_2_accuracy: 0.9982 - dense_11_3_accuracy: 0.9959 - dense_11_4_accuracy: 0.9998 - dense_11_5_accuracy: 0.9948 - dense_11_6_accuracy: 0.9826 - dense_11_7_accuracy: 0.9993 - dense_11_8_accuracy: 0.9852 - dense_11_9_accuracy: 0.9789\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_attention_map(modelx, input_vocabulary, inv_output_vocabulary, text, n_s = 128, num = 7):\n",
        "    \"\"\"\n",
        "    Plot the attention map.\n",
        "\n",
        "    \"\"\"\n",
        "    attention_map = np.zeros((10, 30))\n",
        "    layer = modelx.get_layer('attention_weights')\n",
        "\n",
        "    Ty, Tx = attention_map.shape\n",
        "\n",
        "    human_vocab_size = 37\n",
        "\n",
        "\n",
        "    X = modelx.inputs[0]\n",
        "    s0 = modelx.inputs[1]\n",
        "    c0 = modelx.inputs[2]\n",
        "    s = s0\n",
        "    c = s0\n",
        "\n",
        "    a = modelx.layers[2](X)\n",
        "    outputs = []\n",
        "\n",
        "    for t in range(Ty):\n",
        "        s_prev = s\n",
        "        s_prev = modelx.layers[3](s_prev)\n",
        "        concat = modelx.layers[4]([a, s_prev])\n",
        "        e = modelx.layers[5](concat)\n",
        "        energies = modelx.layers[6](e)\n",
        "        alphas = modelx.layers[7](energies)\n",
        "        context = modelx.layers[8]([alphas, a])\n",
        "        # Don't forget to pass: initial_state = [hidden state, cell state] (≈ 1 line)\n",
        "        s, _, c = modelx.layers[10](context, initial_state = [s, c])\n",
        "        outputs.append(energies)\n",
        "\n",
        "    f = Model(inputs=[X, s0, c0], outputs = outputs)\n",
        "\n",
        "\n",
        "    s0 = np.zeros((1, n_s))\n",
        "    c0 = np.zeros((1, n_s))\n",
        "    encoded = np.array(string_to_int(text, Tx, input_vocabulary)).reshape((1, 30))\n",
        "    encoded = np.array(list(map(lambda x: to_categorical(x, num_classes=len(input_vocabulary)), encoded)))\n",
        "\n",
        "\n",
        "    r = f([encoded, s0, c0])\n",
        "\n",
        "    for t in range(Ty):\n",
        "        for t_prime in range(Tx):\n",
        "            attention_map[t][t_prime] = r[t][0, t_prime]\n",
        "\n",
        "    # Normalize attention map\n",
        "    row_max = attention_map.max(axis=1)\n",
        "    attention_map = attention_map / row_max[:, None]\n",
        "\n",
        "    prediction = modelx.predict([encoded, s0, c0])\n",
        "\n",
        "    predicted_text = []\n",
        "    for i in range(len(prediction)):\n",
        "        predicted_text.append(int(np.argmax(prediction[i], axis=1)))\n",
        "\n",
        "    predicted_text = list(predicted_text)\n",
        "    predicted_text = int_to_string(predicted_text, inv_output_vocabulary)\n",
        "    text_ = list(text)\n",
        "\n",
        "    # get the lengths of the string\n",
        "    input_length = len(text)\n",
        "    output_length = Ty\n",
        "\n",
        "    # Plot the attention_map\n",
        "    plt.clf()\n",
        "    f = plt.figure(figsize=(8, 8.5))\n",
        "    ax = f.add_subplot(1, 1, 1)\n",
        "\n",
        "    # add image\n",
        "    i = ax.imshow(attention_map, interpolation='nearest', cmap='Blues')\n",
        "\n",
        "    # add colorbar\n",
        "    cbaxes = f.add_axes([0.2, 0, 0.6, 0.03])\n",
        "    cbar = f.colorbar(i, cax=cbaxes, orientation='horizontal')\n",
        "    cbar.ax.set_xlabel('Alpha value (Probability output of the \"softmax\")', labelpad=2)\n",
        "\n",
        "    # add labels\n",
        "    ax.set_yticks(range(output_length))\n",
        "    ax.set_yticklabels(predicted_text[:output_length])\n",
        "\n",
        "    ax.set_xticks(range(input_length))\n",
        "    ax.set_xticklabels(text_[:input_length], rotation=45)\n",
        "\n",
        "    ax.set_xlabel('Input Sequence')\n",
        "    ax.set_ylabel('Output Sequence')\n",
        "\n",
        "    # add grid and legend\n",
        "    ax.grid()\n",
        "\n",
        "    #f.show()\n",
        "\n",
        "    return attention_map"
      ],
      "metadata": {
        "id": "jJJ1ymjz2rAW"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EXAMPLES = ['3 May 1979', '5 April 09', '21th of August 2016', 'Tue 10 Jul 2007', 'Saturday May 9 2018', 'March 3 2001', 'March 3rd 2001', '1 March 2001']\n",
        "s00 = np.zeros((1, n_s))\n",
        "c00 = np.zeros((1, n_s))\n",
        "for example in EXAMPLES:\n",
        "    source = string_to_int(example, Tx, human_vocab)\n",
        "    #print(source)\n",
        "    source = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), source))).swapaxes(0,1)\n",
        "    source = np.swapaxes(source, 0, 1)\n",
        "    source = np.expand_dims(source, axis=0)\n",
        "    prediction = model.predict([source, s00, c00])\n",
        "    prediction = np.argmax(prediction, axis = -1)\n",
        "    output = [inv_machine_vocab[int(i)] for i in prediction]\n",
        "    print(\"source:\", example)\n",
        "    print(\"output:\", ''.join(output),\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUjPi27dxO2z",
        "outputId": "ef8b4888-afab-4de7-abf1-88983ef21caa"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 6s 6s/step\n",
            "source: 3 May 1979\n",
            "output: 1979-05-03 \n",
            "\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "source: 5 April 09\n",
            "output: 2009-04-05 \n",
            "\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "source: 21th of August 2016\n",
            "output: 2016-08-21 \n",
            "\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "source: Tue 10 Jul 2007\n",
            "output: 2007-07-10 \n",
            "\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "source: Saturday May 9 2018\n",
            "output: 2018-05-09 \n",
            "\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "source: March 3 2001\n",
            "output: 2001-03-03 \n",
            "\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "source: March 3rd 2001\n",
            "output: 2001-03-03 \n",
            "\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "source: 1 March 2001\n",
            "output: 2001-03-01 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_map = plot_attention_map(model, human_vocab, inv_machine_vocab, \"1983, 09 Oct\", num = 7, n_s = 64);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 670
        },
        "id": "BmLPfXx73AQk",
        "outputId": "b4a6ad0a-eddb-4160-a35a-c16183ca4e60"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 37ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-103-53ace7f8c4f9>:52: RuntimeWarning: invalid value encountered in divide\n",
            "  attention_map = attention_map / row_max[:, None]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x850 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}